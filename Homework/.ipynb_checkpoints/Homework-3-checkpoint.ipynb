{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4744962-cf2d-414d-acf8-38e56a8c5bea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MTH 4224 / CSE 4224 - Homework 3\n",
    "\n",
    "## Classification Models\n",
    "\n",
    "**Deadline**: Mar 15\n",
    "\n",
    "**Points**: 60\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Submit **one** Python notebook file for grading. Your file must include **text explanations** of your work, **well-commented code**, and the **outputs** from your code.\n",
    "\n",
    "### Datasets\n",
    "\n",
    "For problems 1-5, use the [Heart Disease Data Set](https://archive.ics.uci.edu/dataset/45/heart+disease) of patients with and without heart disease. UCI Machine Learning Repository.\n",
    "\n",
    "For porblems 6-10, use the [Mushroom Dataset](https://archive.ics.uci.edu/dataset/73/mushroom) containing details on many types of mushrooms. UCI Machine Learning Repository.\n",
    "\n",
    "### Problems\n",
    "\n",
    "#### Heart Disease Classification\n",
    "\n",
    "1. **[5 points]** Use pairplots to analyze the feature distributions and output labels. Note any strong patterns you observe. (Use only the 14 main features listed.)\n",
    "\n",
    "2. **[10 points]** Do a comparison of the naive Bayes' classifier, logistic regression, LDA, QDA, and K-nearest neighbors on the same train/test split.\n",
    "\n",
    "3. **[5 points]** Train a decision tree classifier to classify which people have heart disease and test it on a test set.\n",
    "\n",
    "4. **[5 points]** Use cost-complexity pruning to simplify your tree as much as possible to maintain high validation accuracy and plot tree diagrams. Discuss what is intuitive (or not intuitive) about the trained model's decisionmaking process.\n",
    "\n",
    "5. **[5 points]** Tune either a random forest or XGBoost classifier, and justify your choice of 1 algorithm over the other.\n",
    "\n",
    "6. **[5 points]** Compute feature importance metrics by both mean decrease in impurity and by permutation importance. Which features do these two metrics and the plotted tree from Problem 4 agree are important? Does this seem practically meaningful?\n",
    "\n",
    "#### Mushrooms. Edible or Poisonous?\n",
    "\n",
    "7. **[5 points]** Preprocess the data into a form for use for classification. Note most features are categorical and will need to be modified into numerical representations.\n",
    "\n",
    "8. **[5 points]** Train a decision tree classifier to classify which mushrooms are poisonous and test it on a test set.\n",
    "\n",
    "9. **[5 points]** Use cost-complexity pruning to simplify your tree as much as possible to maintain high validation accuracy and plot tree diagrams. Discuss what is intuitive (or not intuitive) about the trained model's decisionmaking process.\n",
    "\n",
    "10. **[10 points]** Train a XGBoost model to predict which mushrooms are poisonous and test it on a test set. Tune its hyperparameters to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf5cd03-e11d-4135-a545-e35ff128ebc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
